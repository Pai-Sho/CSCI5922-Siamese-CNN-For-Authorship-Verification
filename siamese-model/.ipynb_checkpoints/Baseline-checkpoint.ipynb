{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Baseline architecture is designed with few layers and large kernels\n",
    "    - 1st convolutional layer uses 32 filters of size 10 x 10 (32, 1, 10, 10)\n",
    "    - 2nd convolutional layer uses 64 filters of size 8 x 8 (64, 1, 8, 8)\n",
    "    - 3rd convolutional layer uses 64 filters of size 4 x 4 (64, 1, 4, 4)\n",
    "    - 1st hidden layers uses 400 neurons (Relu)\n",
    "    - 2nd hidden layer uses 200 hidden units (Relu)\n",
    "    - L2 regularization and dropout with a probability of 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.datasets as dset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from matplotlib.image import imread\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import pickle\n",
    "from Dataset import AuthorsDataset\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineNet(nn.Module):\n",
    "\n",
    "    def __init__(self, input_channels=1):\n",
    "        super(BaselineNet, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=10, bias=False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=8, bias=False)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=4, bias=False)\n",
    "        \n",
    "        self.fc1 = nn.Linear(832896, 400)\n",
    "        self.fc2 = nn.Linear(400, 200)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.fc3 = nn.Linear(200, 2)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.relu(x)\n",
    "                \n",
    "        x = x.view(x.size(0), -1)\n",
    "                \n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "                \n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class BaselineSiamese(nn.Module):\n",
    "\n",
    "    def __init__(self, out_layers=2):\n",
    "        super(BaselineSiamese, self).__init__()\n",
    "\n",
    "        self.baselineNet = BaselineNet()\n",
    "        self.fc1 = nn.Linear(8, 2)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward_once(self, x):\n",
    "\n",
    "        x = self.baselineNet(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def forward(self, x, y):\n",
    "\n",
    "        # Pass examples through siamese resnet\n",
    "        f_x = self.forward_once(x)\n",
    "        f_y = self.forward_once(y)\n",
    "\n",
    "        # Concatenate outputs\n",
    "        squared_diff = (f_x - f_y)**2\n",
    "        hadamard = (f_x * f_y)\n",
    "        x = torch.cat((f_x,f_y,squared_diff,hadamard),1)\n",
    "\n",
    "        # Pass through fully connected layers\n",
    "        x = self.fc1(x)\n",
    "\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10\n",
      "EPOCH: 0\t BATCH: 1\tLOSS = 0.695155\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from Dataset import AuthorsDataset\n",
    "from torch import optim\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from Model import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = BaselineSiamese()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01, momentum=0.9)\n",
    "\n",
    "train_dataset = AuthorsDataset(\n",
    "    root_dir='Dataset',\n",
    "    positive='positive.txt',\n",
    "    negative='negative.txt'\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=16,\n",
    "    num_workers=1,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "for epoch in range(1):\n",
    "\n",
    "    for batch_idx,(X1,X2,Y) in enumerate(train_loader):\n",
    "\n",
    "        Y_hat = model.forward(X1,X2)\n",
    "        \n",
    "        loss = criterion(Y_hat, Y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        print(\"EPOCH: %d\\t BATCH: %d\\tLOSS = %f\"%(epoch,batch_idx,loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
